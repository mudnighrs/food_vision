{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mudnighrs/food_vision/blob/main/food_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f4ks5R63_e6U",
        "outputId": "9ef265b0-d419-42fe-b7b7-97132e584cc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] torch/torchvision versions not as required, installing nightly versions.\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in /usr/local/lib/python3.11/dist-packages (from torch) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.11/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.11/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.11/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /usr/local/lib/python3.11/dist-packages (from torch) (2.26.2)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.11/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.11/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.3.1 in /usr/local/lib/python3.11/dist-packages (from torch) (3.3.1)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.3.1->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "torch version: 2.7.1+cu126\n",
            "torchvision version: 0.22.1+cu126\n"
          ]
        }
      ],
      "source": [
        "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
        "try:\n",
        "    import torch\n",
        "    import torchvision\n",
        "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
        "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")\n",
        "except:\n",
        "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
        "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "    import torch\n",
        "    import torchvision\n",
        "    print(f\"torch version: {torch.__version__}\")\n",
        "    print(f\"torchvision version: {torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aK78PH8PADqn"
      },
      "outputs": [],
      "source": [
        "# Continue with regular imports\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "\n",
        "# Try to get torchinfo, install it if it doesn't work\n",
        "try:\n",
        "    from torchinfo import summary\n",
        "except:\n",
        "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
        "    !pip install -q torchinfo\n",
        "    from torchinfo import summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNSl--MKA2Ug"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Contains functionality for creating PyTorch DataLoaders for\n",
        "image classification data.\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS = os.cpu_count()\n",
        "\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir: str,\n",
        "    transform: transforms.Compose,\n",
        "    batch_size: int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "  \"\"\"Creates training and testing DataLoaders.\n",
        "\n",
        "  Takes in a training directory and testing directory path and turns\n",
        "  them into PyTorch Datasets and then into PyTorch DataLoaders.\n",
        "\n",
        "  Args:\n",
        "    train_dir: Path to training directory.\n",
        "    test_dir: Path to testing directory.\n",
        "    transform: torchvision transforms to perform on training and testing data.\n",
        "    batch_size: Number of samples per batch in each of the DataLoaders.\n",
        "    num_workers: An integer for number of workers per DataLoader.\n",
        "\n",
        "  Returns:\n",
        "    A tuple of (train_dataloader, test_dataloader, class_names).\n",
        "    Where class_names is a list of the target classes.\n",
        "    Example usage:\n",
        "      train_dataloader, test_dataloader, class_names = \\\n",
        "        = create_dataloaders(train_dir=path/to/train_dir,\n",
        "                             test_dir=path/to/test_dir,\n",
        "                             transform=some_transform,\n",
        "                             batch_size=32,\n",
        "                             num_workers=4)\n",
        "  \"\"\"\n",
        "  # Use ImageFolder to create dataset(s)\n",
        "  train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
        "  test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
        "\n",
        "  # Get class names\n",
        "  class_names = train_data.classes\n",
        "\n",
        "  # Turn images into data loaders\n",
        "  train_dataloader = DataLoader(\n",
        "      train_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=True,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "  test_dataloader = DataLoader(\n",
        "      test_data,\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      num_workers=num_workers,\n",
        "      pin_memory=True,\n",
        "  )\n",
        "\n",
        "  return train_dataloader, test_dataloader, class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vgPVKLGzA_Uj"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Contains functions for training and testing a PyTorch model.\n",
        "\"\"\"\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer,\n",
        "               device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Trains a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to training mode and then\n",
        "    runs through all of the required training steps (forward\n",
        "    pass, loss calculation, optimizer step).\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained.\n",
        "    dataloader: A DataLoader instance for the model to be trained on.\n",
        "    loss_fn: A PyTorch loss function to minimize.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of training loss and training accuracy metrics.\n",
        "    In the form (train_loss, train_accuracy). For example:\n",
        "\n",
        "    (0.1112, 0.8743)\n",
        "    \"\"\"\n",
        "    # Put model in train mode\n",
        "    model.train()\n",
        "\n",
        "    # Setup train loss and train accuracy values\n",
        "    train_loss, train_acc = 0, 0\n",
        "\n",
        "    # Loop through data loader data batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Send data to target device\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 1. Forward pass\n",
        "        y_pred = model(X)\n",
        "\n",
        "        # 2. Calculate  and accumulate loss\n",
        "        loss = loss_fn(y_pred, y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # 3. Optimizer zero grad\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # 4. Loss backward\n",
        "        loss.backward()\n",
        "\n",
        "        # 5. Optimizer step\n",
        "        optimizer.step()\n",
        "\n",
        "        # Calculate and accumulate accuracy metric across all batches\n",
        "        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    train_loss = train_loss / len(dataloader)\n",
        "    train_acc = train_acc / len(dataloader)\n",
        "    return train_loss, train_acc\n",
        "\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "    \"\"\"Tests a PyTorch model for a single epoch.\n",
        "\n",
        "    Turns a target PyTorch model to \"eval\" mode and then performs\n",
        "    a forward pass on a testing dataset.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be tested.\n",
        "    dataloader: A DataLoader instance for the model to be tested on.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on the test data.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A tuple of testing loss and testing accuracy metrics.\n",
        "    In the form (test_loss, test_accuracy). For example:\n",
        "\n",
        "    (0.0223, 0.8985)\n",
        "    \"\"\"\n",
        "    # Put model in eval mode\n",
        "    model.eval()\n",
        "\n",
        "    # Setup test loss and test accuracy values\n",
        "    test_loss, test_acc = 0, 0\n",
        "\n",
        "    # Turn on inference context manager\n",
        "    with torch.inference_mode():\n",
        "        # Loop through DataLoader batches\n",
        "        for batch, (X, y) in enumerate(dataloader):\n",
        "            # Send data to target device\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            # 1. Forward pass\n",
        "            test_pred_logits = model(X)\n",
        "\n",
        "            # 2. Calculate and accumulate loss\n",
        "            loss = loss_fn(test_pred_logits, y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            # Calculate and accumulate accuracy\n",
        "            test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "            test_acc += ((test_pred_labels == y).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    # Adjust metrics to get average loss and accuracy per batch\n",
        "    test_loss = test_loss / len(dataloader)\n",
        "    test_acc = test_acc / len(dataloader)\n",
        "    return test_loss, test_acc\n",
        "\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module,\n",
        "          epochs: int,\n",
        "          device: torch.device) -> Dict[str, List]:\n",
        "    \"\"\"Trains and tests a PyTorch model.\n",
        "\n",
        "    Passes a target PyTorch models through train_step() and test_step()\n",
        "    functions for a number of epochs, training and testing the model\n",
        "    in the same epoch loop.\n",
        "\n",
        "    Calculates, prints and stores evaluation metrics throughout.\n",
        "\n",
        "    Args:\n",
        "    model: A PyTorch model to be trained and tested.\n",
        "    train_dataloader: A DataLoader instance for the model to be trained on.\n",
        "    test_dataloader: A DataLoader instance for the model to be tested on.\n",
        "    optimizer: A PyTorch optimizer to help minimize the loss function.\n",
        "    loss_fn: A PyTorch loss function to calculate loss on both datasets.\n",
        "    epochs: An integer indicating how many epochs to train for.\n",
        "    device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n",
        "\n",
        "    Returns:\n",
        "    A dictionary of training and testing loss as well as training and\n",
        "    testing accuracy metrics. Each metric has a value in a list for\n",
        "    each epoch.\n",
        "    In the form: {train_loss: [...],\n",
        "              train_acc: [...],\n",
        "              test_loss: [...],\n",
        "              test_acc: [...]}\n",
        "    For example if training for epochs=2:\n",
        "             {train_loss: [2.0616, 1.0537],\n",
        "              train_acc: [0.3945, 0.3945],\n",
        "              test_loss: [1.2641, 1.5706],\n",
        "              test_acc: [0.3400, 0.2973]}\n",
        "    \"\"\"\n",
        "    # Create empty results dictionary\n",
        "    results = {\"train_loss\": [],\n",
        "               \"train_acc\": [],\n",
        "               \"test_loss\": [],\n",
        "               \"test_acc\": []\n",
        "    }\n",
        "\n",
        "    # Make sure model on target device\n",
        "    model.to(device)\n",
        "\n",
        "    # Loop through training and testing steps for a number of epochs\n",
        "    for epoch in tqdm(range(epochs)):\n",
        "        train_loss, train_acc = train_step(model=model,\n",
        "                                          dataloader=train_dataloader,\n",
        "                                          loss_fn=loss_fn,\n",
        "                                          optimizer=optimizer,\n",
        "                                          device=device)\n",
        "        test_loss, test_acc = test_step(model=model,\n",
        "          dataloader=test_dataloader,\n",
        "          loss_fn=loss_fn,\n",
        "          device=device)\n",
        "\n",
        "        # Print out what's happening\n",
        "        print(\n",
        "          f\"Epoch: {epoch+1} | \"\n",
        "          f\"train_loss: {train_loss:.4f} | \"\n",
        "          f\"train_acc: {train_acc:.4f} | \"\n",
        "          f\"test_loss: {test_loss:.4f} | \"\n",
        "          f\"test_acc: {test_acc:.4f}\"\n",
        "        )\n",
        "\n",
        "        # Update results dictionary\n",
        "        results[\"train_loss\"].append(train_loss)\n",
        "        results[\"train_acc\"].append(train_acc)\n",
        "        results[\"test_loss\"].append(test_loss)\n",
        "        results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    # Return the filled results at the end of the epochs\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pllxi4oZBrLl"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A series of helper functions used throughout the course.\n",
        "\n",
        "If a function gets defined once and could be used over and over, it'll go in here.\n",
        "\"\"\"\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "import requests\n",
        "\n",
        "# Walk through an image classification directory and find out how many files (images)\n",
        "# are in each subdirectory.\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "    \"\"\"\n",
        "    Walks through dir_path returning its contents.\n",
        "    Args:\n",
        "    dir_path (str): target directory\n",
        "\n",
        "    Returns:\n",
        "    A print out of:\n",
        "      number of subdiretories in dir_path\n",
        "      number of images (files) in each subdirectory\n",
        "      name of each subdirectory\n",
        "    \"\"\"\n",
        "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
        "\n",
        "def plot_decision_boundary(model: torch.nn.Module, X: torch.Tensor, y: torch.Tensor):\n",
        "    \"\"\"Plots decision boundaries of model predicting on X in comparison to y.\n",
        "\n",
        "    Source - https://madewithml.com/courses/foundations/neural-networks/ (with modifications)\n",
        "    \"\"\"\n",
        "    # Put everything to CPU (works better with NumPy + Matplotlib)\n",
        "    model.to(\"cpu\")\n",
        "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "    # Setup prediction boundaries and grid\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
        "\n",
        "    # Make features\n",
        "    X_to_pred_on = torch.from_numpy(np.column_stack((xx.ravel(), yy.ravel()))).float()\n",
        "\n",
        "    # Make predictions\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        y_logits = model(X_to_pred_on)\n",
        "\n",
        "    # Test for multi-class or binary and adjust logits to prediction labels\n",
        "    if len(torch.unique(y)) > 2:\n",
        "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)  # mutli-class\n",
        "    else:\n",
        "        y_pred = torch.round(torch.sigmoid(y_logits))  # binary\n",
        "\n",
        "    # Reshape preds and plot\n",
        "    y_pred = y_pred.reshape(xx.shape).detach().numpy()\n",
        "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())\n",
        "\n",
        "\n",
        "# Plot linear data or training and test and predictions (optional)\n",
        "def plot_predictions(\n",
        "    train_data, train_labels, test_data, test_labels, predictions=None\n",
        "):\n",
        "    \"\"\"\n",
        "  Plots linear training data and test data and compares predictions.\n",
        "  \"\"\"\n",
        "    plt.figure(figsize=(10, 7))\n",
        "\n",
        "    # Plot training data in blue\n",
        "    plt.scatter(train_data, train_labels, c=\"b\", s=4, label=\"Training data\")\n",
        "\n",
        "    # Plot test data in green\n",
        "    plt.scatter(test_data, test_labels, c=\"g\", s=4, label=\"Testing data\")\n",
        "\n",
        "    if predictions is not None:\n",
        "        # Plot the predictions in red (predictions were made on the test data)\n",
        "        plt.scatter(test_data, predictions, c=\"r\", s=4, label=\"Predictions\")\n",
        "\n",
        "    # Show the legend\n",
        "    plt.legend(prop={\"size\": 14})\n",
        "\n",
        "\n",
        "# Calculate accuracy (a classification metric)\n",
        "def accuracy_fn(y_true, y_pred):\n",
        "    \"\"\"Calculates accuracy between truth labels and predictions.\n",
        "\n",
        "    Args:\n",
        "        y_true (torch.Tensor): Truth labels for predictions.\n",
        "        y_pred (torch.Tensor): Predictions to be compared to predictions.\n",
        "\n",
        "    Returns:\n",
        "        [torch.float]: Accuracy value between y_true and y_pred, e.g. 78.45\n",
        "    \"\"\"\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "    return acc\n",
        "\n",
        "\n",
        "def print_train_time(start, end, device=None):\n",
        "    \"\"\"Prints difference between start and end time.\n",
        "\n",
        "    Args:\n",
        "        start (float): Start time of computation (preferred in timeit format).\n",
        "        end (float): End time of computation.\n",
        "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
        "\n",
        "    Returns:\n",
        "        float: time between start and end in seconds (higher is longer).\n",
        "    \"\"\"\n",
        "    total_time = end - start\n",
        "    print(f\"\\nTrain time on {device}: {total_time:.3f} seconds\")\n",
        "    return total_time\n",
        "\n",
        "\n",
        "# Plot loss curves of a model\n",
        "def plot_loss_curves(results):\n",
        "    \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "    Args:\n",
        "        results (dict): dictionary containing list of values, e.g.\n",
        "            {\"train_loss\": [...],\n",
        "             \"train_acc\": [...],\n",
        "             \"test_loss\": [...],\n",
        "             \"test_acc\": [...]}\n",
        "    \"\"\"\n",
        "    loss = results[\"train_loss\"]\n",
        "    test_loss = results[\"test_loss\"]\n",
        "\n",
        "    accuracy = results[\"train_acc\"]\n",
        "    test_accuracy = results[\"test_acc\"]\n",
        "\n",
        "    epochs = range(len(results[\"train_loss\"]))\n",
        "\n",
        "    plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, loss, label=\"train_loss\")\n",
        "    plt.plot(epochs, test_loss, label=\"test_loss\")\n",
        "    plt.title(\"Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, accuracy, label=\"train_accuracy\")\n",
        "    plt.plot(epochs, test_accuracy, label=\"test_accuracy\")\n",
        "    plt.title(\"Accuracy\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "# Pred and plot image function from notebook 04\n",
        "# See creation: https://www.learnpytorch.io/04_pytorch_custom_datasets/#113-putting-custom-image-prediction-together-building-a-function\n",
        "from typing import List\n",
        "import torchvision\n",
        "\n",
        "\n",
        "def pred_and_plot_image(\n",
        "    model: torch.nn.Module,\n",
        "    image_path: str,\n",
        "    class_names: List[str] = None,\n",
        "    transform=None,\n",
        "    device: torch.device = \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "):\n",
        "    \"\"\"Makes a prediction on a target image with a trained model and plots the image.\n",
        "\n",
        "    Args:\n",
        "        model (torch.nn.Module): trained PyTorch image classification model.\n",
        "        image_path (str): filepath to target image.\n",
        "        class_names (List[str], optional): different class names for target image. Defaults to None.\n",
        "        transform (_type_, optional): transform of target image. Defaults to None.\n",
        "        device (torch.device, optional): target device to compute on. Defaults to \"cuda\" if torch.cuda.is_available() else \"cpu\".\n",
        "\n",
        "    Returns:\n",
        "        Matplotlib plot of target image and model prediction as title.\n",
        "\n",
        "    Example usage:\n",
        "        pred_and_plot_image(model=model,\n",
        "                            image=\"some_image.jpeg\",\n",
        "                            class_names=[\"class_1\", \"class_2\", \"class_3\"],\n",
        "                            transform=torchvision.transforms.ToTensor(),\n",
        "                            device=device)\n",
        "    \"\"\"\n",
        "\n",
        "    # 1. Load in image and convert the tensor values to float32\n",
        "    target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "    # 2. Divide the image pixel values by 255 to get them between [0, 1]\n",
        "    target_image = target_image / 255.0\n",
        "\n",
        "    # 3. Transform if necessary\n",
        "    if transform:\n",
        "        target_image = transform(target_image)\n",
        "\n",
        "    # 4. Make sure the model is on the target device\n",
        "    model.to(device)\n",
        "\n",
        "    # 5. Turn on model evaluation mode and inference mode\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Add an extra dimension to the image\n",
        "        target_image = target_image.unsqueeze(dim=0)\n",
        "\n",
        "        # Make a prediction on image with an extra dimension and send it to the target device\n",
        "        target_image_pred = model(target_image.to(device))\n",
        "\n",
        "    # 6. Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
        "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "    # 7. Convert prediction probabilities -> prediction labels\n",
        "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "    # 8. Plot the image alongside the prediction and prediction probability\n",
        "    plt.imshow(\n",
        "        target_image.squeeze().permute(1, 2, 0)\n",
        "    )  # make sure it's the right size for matplotlib\n",
        "    if class_names:\n",
        "        title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    else:\n",
        "        title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "    plt.title(title)\n",
        "    plt.axis(False)\n",
        "\n",
        "def set_seeds(seed: int=42):\n",
        "    \"\"\"Sets random sets for torch operations.\n",
        "\n",
        "    Args:\n",
        "        seed (int, optional): Random seed to set. Defaults to 42.\n",
        "    \"\"\"\n",
        "    # Set the seed for general torch operations\n",
        "    torch.manual_seed(seed)\n",
        "    # Set the seed for CUDA torch operations (ones that happen on the GPU)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "def download_data(source: str,\n",
        "                  destination: str,\n",
        "                  remove_source: bool = True) -> Path:\n",
        "    \"\"\"Downloads a zipped dataset from source and unzips to destination.\n",
        "\n",
        "    Args:\n",
        "        source (str): A link to a zipped file containing data.\n",
        "        destination (str): A target directory to unzip data to.\n",
        "        remove_source (bool): Whether to remove the source after downloading and extracting.\n",
        "\n",
        "    Returns:\n",
        "        pathlib.Path to downloaded data.\n",
        "\n",
        "    Example usage:\n",
        "        download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
        "                      destination=\"pizza_steak_sushi\")\n",
        "    \"\"\"\n",
        "    # Setup path to data folder\n",
        "    data_path = Path(\"data/\")\n",
        "    image_path = data_path / destination\n",
        "\n",
        "    # If the image folder doesn't exist, download it and prepare it...\n",
        "    if image_path.is_dir():\n",
        "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
        "    else:\n",
        "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
        "        image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Download pizza, steak, sushi data\n",
        "        target_file = Path(source).name\n",
        "        with open(data_path / target_file, \"wb\") as f:\n",
        "            request = requests.get(source)\n",
        "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
        "            f.write(request.content)\n",
        "\n",
        "        # Unzip pizza, steak, sushi data\n",
        "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
        "            print(f\"[INFO] Unzipping {target_file} data...\")\n",
        "            zip_ref.extractall(image_path)\n",
        "\n",
        "        # Remove .zip file\n",
        "        if remove_source:\n",
        "            os.remove(data_path / target_file)\n",
        "\n",
        "    return image_path"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Contains various utility functions for PyTorch model training and saving.\n",
        "\"\"\"\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "    \"\"\"Saves a PyTorch model to a target directory.\n",
        "\n",
        "    Args:\n",
        "    model: A target PyTorch model to save.\n",
        "    target_dir: A directory for saving the model to.\n",
        "    model_name: A filename for the saved model. Should include\n",
        "      either \".pth\" or \".pt\" as the file extension.\n",
        "\n",
        "    Example usage:\n",
        "    save_model(model=model_0,\n",
        "               target_dir=\"models\",\n",
        "               model_name=\"05_going_modular_tingvgg_model.pth\")\n",
        "    \"\"\"\n",
        "    # Create target directory\n",
        "    target_dir_path = Path(target_dir)\n",
        "    target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "\n",
        "    # Create model save path\n",
        "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "    model_save_path = target_dir_path / model_name\n",
        "\n",
        "    # Save the model state_dict()\n",
        "    print(f\"[INFO] Saving model to: {model_save_path}\")\n",
        "    torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "H6dBOtLC6vGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRBAq52zB3TX"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "with zipfile.ZipFile(\"/content/drive/MyDrive/archive-13.zip\", 'r') as zip_ref:\n",
        "     zip_ref.extractall(\"unzipped_dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6-Ujn21D_0g",
        "outputId": "27b86df8-3ecf-4e0a-b634-6ac840b02f99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "def move_images(split_file, source_dir, target_root):\n",
        "    with open(split_file, 'r') as f:\n",
        "        lines = [line.strip() for line in f]\n",
        "\n",
        "    for line in tqdm(lines, desc=f'Processing {split_file}'):\n",
        "        class_name, img_id = line.split('/')\n",
        "        src = os.path.join(source_dir, class_name, img_id + '.jpg')\n",
        "        dst_dir = os.path.join(target_root, class_name)\n",
        "        os.makedirs(dst_dir, exist_ok=True)\n",
        "        dst = os.path.join(dst_dir, img_id + '.jpg')\n",
        "        shutil.move(src, dst)  # or use shutil.move() to move instead of copy\n",
        "\n",
        "# Paths\n",
        "base_dir = '/content/unzipped_dataset/food-101/food-101'\n",
        "source_images_dir = os.path.join(base_dir, 'images')\n",
        "meta_dir = os.path.join(base_dir, 'meta')\n",
        "\n",
        "# Create train and test folders\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Process\n",
        "move_images(os.path.join(meta_dir, 'train.txt'), source_images_dir, train_dir)\n",
        "move_images(os.path.join(meta_dir, 'test.txt'), source_images_dir, test_dir)\n",
        "\n",
        "print(\" Dataset restructuring complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6T_fzMZRkvj",
        "outputId": "5a932240-de99-4fa2-b620-32b99e316130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing /content/unzipped_dataset/food-101/food-101/meta/train.txt: 100%|██████████| 75750/75750 [00:04<00:00, 17816.90it/s]\n",
            "Processing /content/unzipped_dataset/food-101/food-101/meta/test.txt: 100%|██████████| 25250/25250 [00:03<00:00, 8258.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Dataset restructuring complete!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup directory paths to train and test images\n",
        "train_dir = \"/content/unzipped_dataset/food-101/food-101/train\"\n",
        "test_dir = \"/content/unzipped_dataset/food-101/food-101/test\""
      ],
      "metadata": {
        "id": "7997cG3-UF8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup pretrained EffNetB2 weights\n",
        "effnetb2_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "# 2. Get EffNetB2 transforms\n",
        "effnetb2_transforms = effnetb2_weights.transforms()\n",
        "\n",
        "# 3. Setup pretrained model\n",
        "effnetb2 = torchvision.models.efficientnet_b2(weights=effnetb2_weights) # could also use weights=\"DEFAULT\"\n",
        "\n",
        "# 4. Freeze the base layers in the model (this will freeze all layers to begin with)\n",
        "for param in effnetb2.parameters():\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUGOsbHYUyh3",
        "outputId": "02eafe07-c691-4d9b-b899-468b188460d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35.2M/35.2M [00:00<00:00, 79.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out EffNetB2 classifier head\n",
        "effnetb2.classifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jE-w-Pb1U3aW",
        "outputId": "fab43067-59d7-48c9-bd1a-342f2684446d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Dropout(p=0.3, inplace=True)\n",
              "  (1): Linear(in_features=1408, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9BuUUPRZWFFw",
        "outputId": "838b0e7f-a15e-43ea-b1d5-19315dc716a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Update the classifier head\n",
        "effnetb2.classifier = nn.Sequential(\n",
        "    nn.Dropout(p=0.3, inplace=True), # keep dropout layer same\n",
        "    nn.Linear(in_features=1408, # keep in_features same\n",
        "              out_features=101)) # change out_features to suit our number of classes"
      ],
      "metadata": {
        "id": "dyPi4-eiVCBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=42):\n",
        "    \"\"\"Creates an EfficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of classes in the classifier head.\n",
        "            Defaults to 3.\n",
        "        seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): EffNetB2 feature extractor model.\n",
        "        transforms (torchvision.transforms): EffNetB2 image transforms.\n",
        "    \"\"\"\n",
        "    # 1, 2, 3. Create EffNetB2 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    # 4. Freeze all layers in base model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # 5. Change classifier head with random seed for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=num_classes),\n",
        "    )\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "enMCtymPVh7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "\n",
        "# Print EffNetB2 model summary (uncomment for full output)\n",
        "summary(effnetb2,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1LIbySZSVn-b",
        "outputId": "382b114d-1d93-4126-9afd-e580e72437f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "============================================================================================================================================\n",
              "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
              "============================================================================================================================================\n",
              "EfficientNet (EfficientNet)                                  [1, 3, 224, 224]     [1, 101]             --                   Partial\n",
              "├─Sequential (features)                                      [1, 3, 224, 224]     [1, 1408, 7, 7]      --                   False\n",
              "│    └─Conv2dNormActivation (0)                              [1, 3, 224, 224]     [1, 32, 112, 112]    --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 3, 224, 224]     [1, 32, 112, 112]    (864)                False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 32, 112, 112]    [1, 32, 112, 112]    (64)                 False\n",
              "│    │    └─SiLU (2)                                         [1, 32, 112, 112]    [1, 32, 112, 112]    --                   --\n",
              "│    └─Sequential (1)                                        [1, 32, 112, 112]    [1, 16, 112, 112]    --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 32, 112, 112]    [1, 16, 112, 112]    (1,448)              False\n",
              "│    │    └─MBConv (1)                                       [1, 16, 112, 112]    [1, 16, 112, 112]    (612)                False\n",
              "│    └─Sequential (2)                                        [1, 16, 112, 112]    [1, 24, 56, 56]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 16, 112, 112]    [1, 24, 56, 56]      (6,004)              False\n",
              "│    │    └─MBConv (1)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    │    └─MBConv (2)                                       [1, 24, 56, 56]      [1, 24, 56, 56]      (10,710)             False\n",
              "│    └─Sequential (3)                                        [1, 24, 56, 56]      [1, 48, 28, 28]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 24, 56, 56]      [1, 48, 28, 28]      (16,518)             False\n",
              "│    │    └─MBConv (1)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    │    └─MBConv (2)                                       [1, 48, 28, 28]      [1, 48, 28, 28]      (43,308)             False\n",
              "│    └─Sequential (4)                                        [1, 48, 28, 28]      [1, 88, 14, 14]      --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 48, 28, 28]      [1, 88, 14, 14]      (50,300)             False\n",
              "│    │    └─MBConv (1)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (2)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    │    └─MBConv (3)                                       [1, 88, 14, 14]      [1, 88, 14, 14]      (123,750)            False\n",
              "│    └─Sequential (5)                                        [1, 88, 14, 14]      [1, 120, 14, 14]     --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 88, 14, 14]      [1, 120, 14, 14]     (149,158)            False\n",
              "│    │    └─MBConv (1)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (2)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    │    └─MBConv (3)                                       [1, 120, 14, 14]     [1, 120, 14, 14]     (237,870)            False\n",
              "│    └─Sequential (6)                                        [1, 120, 14, 14]     [1, 208, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 120, 14, 14]     [1, 208, 7, 7]       (301,406)            False\n",
              "│    │    └─MBConv (1)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (2)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (3)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    │    └─MBConv (4)                                       [1, 208, 7, 7]       [1, 208, 7, 7]       (686,868)            False\n",
              "│    └─Sequential (7)                                        [1, 208, 7, 7]       [1, 352, 7, 7]       --                   False\n",
              "│    │    └─MBConv (0)                                       [1, 208, 7, 7]       [1, 352, 7, 7]       (846,900)            False\n",
              "│    │    └─MBConv (1)                                       [1, 352, 7, 7]       [1, 352, 7, 7]       (1,888,920)          False\n",
              "│    └─Conv2dNormActivation (8)                              [1, 352, 7, 7]       [1, 1408, 7, 7]      --                   False\n",
              "│    │    └─Conv2d (0)                                       [1, 352, 7, 7]       [1, 1408, 7, 7]      (495,616)            False\n",
              "│    │    └─BatchNorm2d (1)                                  [1, 1408, 7, 7]      [1, 1408, 7, 7]      (2,816)              False\n",
              "│    │    └─SiLU (2)                                         [1, 1408, 7, 7]      [1, 1408, 7, 7]      --                   --\n",
              "├─AdaptiveAvgPool2d (avgpool)                                [1, 1408, 7, 7]      [1, 1408, 1, 1]      --                   --\n",
              "├─Sequential (classifier)                                    [1, 1408]            [1, 101]             --                   True\n",
              "│    └─Dropout (0)                                           [1, 1408]            [1, 1408]            --                   --\n",
              "│    └─Linear (1)                                            [1, 1408]            [1, 101]             142,309              True\n",
              "============================================================================================================================================\n",
              "Total params: 7,843,303\n",
              "Trainable params: 142,309\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (Units.MEGABYTES): 657.78\n",
              "============================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.80\n",
              "Params size (MB): 31.37\n",
              "Estimated Total Size (MB): 188.77\n",
              "============================================================================================================================================"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_dataloader_effnetb2, test_dataloader_effnetb2, class_names = create_dataloaders(train_dir=train_dir,\n",
        "                                                                                                 test_dir=test_dir,\n",
        "                                                                                                 transform=effnetb2_transforms,\n",
        "                                                                                                 batch_size=32)"
      ],
      "metadata": {
        "id": "N4mcAYb4VuRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(params=effnetb2.parameters(),\n",
        "                             lr=1e-3)\n",
        "# Setup loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Set seeds for reproducibility and train the model\n",
        "set_seeds()\n",
        "effnetb2_results = train(model=effnetb2,\n",
        "                                train_dataloader=train_dataloader_effnetb2,\n",
        "                                test_dataloader=test_dataloader_effnetb2,\n",
        "                                epochs=10,\n",
        "                                optimizer=optimizer,\n",
        "                                loss_fn=loss_fn,\n",
        "                                device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wioHEHpV4wp",
        "outputId": "cc23df07-c1f5-4ed3-fd5e-8e81ce19d563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 1/10 [15:03<2:15:34, 903.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | train_loss: 2.1047 | train_acc: 0.4995 | test_loss: 1.6140 | test_acc: 0.5989\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 20%|██        | 2/10 [29:56<1:59:38, 897.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2 | train_loss: 1.9124 | train_acc: 0.5280 | test_loss: 1.4943 | test_acc: 0.6183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 30%|███       | 3/10 [44:44<1:44:10, 892.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3 | train_loss: 1.8471 | train_acc: 0.5384 | test_loss: 1.4490 | test_acc: 0.6260\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 40%|████      | 4/10 [59:24<1:28:47, 887.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4 | train_loss: 1.8052 | train_acc: 0.5480 | test_loss: 1.4370 | test_acc: 0.6274\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 50%|█████     | 5/10 [1:13:32<1:12:47, 873.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5 | train_loss: 1.7867 | train_acc: 0.5512 | test_loss: 1.4193 | test_acc: 0.6344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 60%|██████    | 6/10 [1:27:33<57:29, 862.46s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 6 | train_loss: 1.7755 | train_acc: 0.5558 | test_loss: 1.4277 | test_acc: 0.6301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 70%|███████   | 7/10 [1:41:34<42:46, 855.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 7 | train_loss: 1.7683 | train_acc: 0.5561 | test_loss: 1.3968 | test_acc: 0.6341\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 80%|████████  | 8/10 [1:55:39<28:24, 852.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 8 | train_loss: 1.7633 | train_acc: 0.5570 | test_loss: 1.4132 | test_acc: 0.6331\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r 90%|█████████ | 9/10 [2:09:37<14:07, 847.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 9 | train_loss: 1.7559 | train_acc: 0.5573 | test_loss: 1.4259 | test_acc: 0.6290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [2:23:44<00:00, 862.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 10 | train_loss: 1.7572 | train_acc: 0.5599 | test_loss: 1.4000 | test_acc: 0.6364\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(effnetb2_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "GjA0cO1mY2BY",
        "outputId": "b9f916c2-0ea1-4bed-b1a6-4241f0d61cec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model\n",
        "save_model(model=effnetb2,\n",
        "                 target_dir=\"/content/drive/MyDrive/Food101\",\n",
        "                 model_name=\"pretrained_effnetb2.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YBwadyMYut8",
        "outputId": "61ada8e2-46f5-4f29-9a8b-1e8c8940fc3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving model to: /content/drive/MyDrive/Food101/pretrained_effnetb2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IkpsE67yj4p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Get the model size in bytes then convert to megabytes\n",
        "pretrained_effnetb2_model_size = Path(\"/content/drive/MyDrive/Food101/pretrained_effnetb2.pth\").stat().st_size // (1024*1024) # division converts bytes to megabytes (roughly)\n",
        "print(f\"Pretrained EffNetB2 feature extractor model size: {pretrained_effnetb2_model_size} MB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P24I0a5vkpr6",
        "outputId": "7224233c-28b1-41ca-9091-b7be24e43a84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained EffNetB2 feature extractor model size: 30 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count number of parameters in EffNetB2\n",
        "effnetb2_total_params = sum(torch.numel(param) for param in effnetb2.parameters())\n",
        "effnetb2_total_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CauIu5WlFd0",
        "outputId": "7b041da6-a32a-4b85-a4e2-36c2c96ba9a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7843303"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary with EffNetB2 statistics\n",
        "effnetb2_stats = {\"test_loss\": effnetb2_results[\"test_loss\"][-1],\n",
        "                  \"test_acc\": effnetb2_results[\"test_acc\"][-1],\n",
        "                  \"number_of_parameters\": effnetb2_total_params,\n",
        "                  \"model_size (MB)\": pretrained_effnetb2_model_size}\n",
        "effnetb2_stats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NgUfGh8lIje",
        "outputId": "01eb0aeb-6dc7-48f0-b08b-bf8a1a8b4c00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 1.3999702017235605,\n",
              " 'test_acc': 0.6364319620253165,\n",
              " 'number_of_parameters': 7843303,\n",
              " 'model_size (MB)': 30}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Create FoodVision  demo path\n",
        "foodvision_demo_path = Path(\"demos/foodvision/\")\n",
        "\n",
        "# Make FoodVision  demo directory\n",
        "foodvision_demo_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Make FoodVision  demo examples directory\n",
        "(foodvision_demo_path / \"examples\").mkdir(parents=True, exist_ok=True)\n"
      ],
      "metadata": {
        "id": "KooDXFMprJWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and move an example image\n",
        "!mv /content/drive/MyDrive/Example.jpg demos/foodvision/examples/Example.jpg\n",
        "\n",
        "# Move trained model to FoodVision Big demo folder (will error if model is already moved)\n",
        "!mv /content/drive/MyDrive/Food101/pretrained_effnetb2.pth demos/foodvision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOkHfTxww5J5",
        "outputId": "bd5bc1d9-69df-4bde-f30e-c2660dc4d895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/content/drive/MyDrive/Example.jpg': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out the first 10 Food101 class names\n",
        "# Get Food101 class names\n",
        "food101_class_names = [\n",
        "    \"apple_pie\",\n",
        "    \"baby_back_ribs\",\n",
        "    \"baklava\",\n",
        "    \"beef_carpaccio\",\n",
        "    \"beef_tartare\",\n",
        "    \"beet_salad\",\n",
        "    \"beignets\",\n",
        "    \"bibimbap\",\n",
        "    \"bread_pudding\",\n",
        "    \"breakfast_burrito\",\n",
        "    \"bruschetta\",\n",
        "    \"caesar_salad\",\n",
        "    \"cannoli\",\n",
        "    \"caprese_salad\",\n",
        "    \"carrot_cake\",\n",
        "    \"ceviche\",\n",
        "    \"cheesecake\",\n",
        "    \"cheese_plate\",\n",
        "    \"chicken_curry\",\n",
        "    \"chicken_quesadilla\",\n",
        "    \"chicken_wings\",\n",
        "    \"chocolate_cake\",\n",
        "    \"chocolate_mousse\",\n",
        "    \"churros\",\n",
        "    \"clam_chowder\",\n",
        "    \"club_sandwich\",\n",
        "    \"crab_cakes\",\n",
        "    \"creme_brulee\",\n",
        "    \"croque_madame\",\n",
        "    \"cup_cakes\",\n",
        "    \"deviled_eggs\",\n",
        "    \"donuts\",\n",
        "    \"dumplings\",\n",
        "    \"edamame\",\n",
        "    \"eggs_benedict\",\n",
        "    \"escargots\",\n",
        "    \"falafel\",\n",
        "    \"filet_mignon\",\n",
        "    \"fish_and_chips\",\n",
        "    \"foie_gras\",\n",
        "    \"french_fries\",\n",
        "    \"french_onion_soup\",\n",
        "    \"french_toast\",\n",
        "    \"fried_calamari\",\n",
        "    \"fried_rice\",\n",
        "    \"frozen_yogurt\",\n",
        "    \"garlic_bread\",\n",
        "    \"gnocchi\",\n",
        "    \"greek_salad\",\n",
        "    \"grilled_cheese_sandwich\",\n",
        "    \"grilled_salmon\",\n",
        "    \"guacamole\",\n",
        "    \"gyoza\",\n",
        "    \"hamburger\",\n",
        "    \"hot_and_sour_soup\",\n",
        "    \"hot_dog\",\n",
        "    \"huevos_rancheros\",\n",
        "    \"hummus\",\n",
        "    \"ice_cream\",\n",
        "    \"lasagna\",\n",
        "    \"lobster_bisque\",\n",
        "    \"lobster_roll_sandwich\",\n",
        "    \"macaroni_and_cheese\",\n",
        "    \"macarons\",\n",
        "    \"miso_soup\",\n",
        "    \"mussels\",\n",
        "    \"nachos\",\n",
        "    \"omelette\",\n",
        "    \"onion_rings\",\n",
        "    \"oysters\",\n",
        "    \"pad_thai\",\n",
        "    \"paella\",\n",
        "    \"pancakes\",\n",
        "    \"panna_cotta\",\n",
        "    \"peking_duck\",\n",
        "    \"pho\",\n",
        "    \"pizza\",\n",
        "    \"pork_chop\",\n",
        "    \"poutine\",\n",
        "    \"prime_rib\",\n",
        "    \"pulled_pork_sandwich\",\n",
        "    \"ramen\",\n",
        "    \"ravioli\",\n",
        "    \"red_velvet_cake\",\n",
        "    \"risotto\",\n",
        "    \"samosa\",\n",
        "    \"sashimi\",\n",
        "    \"scallops\",\n",
        "    \"seaweed_salad\",\n",
        "    \"shrimp_and_grits\",\n",
        "    \"spaghetti_bolognese\",\n",
        "    \"spaghetti_carbonara\",\n",
        "    \"spring_rolls\",\n",
        "    \"steak\",\n",
        "    \"strawberry_shortcake\",\n",
        "    \"sushi\",\n",
        "    \"tacos\",\n",
        "    \"takoyaki\",\n",
        "    \"tiramisu\",\n",
        "    \"tuna_tartare\",\n",
        "    \"waffles\"\n",
        "]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FrDmPq89zb-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create path to Food101 class names\n",
        "foodvision_class_names_path = foodvision_demo_path / \"class_names.txt\"\n",
        "\n",
        "# Write Food101 class names list to file\n",
        "with open(foodvision_class_names_path, \"w\") as f:\n",
        "    print(f\"[INFO] Saving Food101 class names to {foodvision_class_names_path}\")\n",
        "    f.write(\"\\n\".join(food101_class_names)) # leave a new line between each class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIqZzhQTzgX8",
        "outputId": "b7138353-6f60-482b-b22e-09bd13bb287c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Saving Food101 class names to demos/foodvision/class_names.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Open Food101 class names file and read each line into a list\n",
        "with open(foodvision_class_names_path, \"r\") as f:\n",
        "    food101_class_names_loaded = [food.strip() for food in  f.readlines()]\n",
        "\n",
        "# View the first 5 class names loaded back in\n",
        "food101_class_names_loaded[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "irMnID-Kz8me",
        "outputId": "533c81f2-3247-4ebf-fe16-6ddbdd9fe55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare']"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/foodvision/model.py\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from torch import nn\n",
        "\n",
        "\n",
        "def create_effnetb2_model(num_classes:int=3,\n",
        "                          seed:int=42):\n",
        "    \"\"\"Creates an EfficientNetB2 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of classes in the classifier head.\n",
        "            Defaults to 3.\n",
        "        seed (int, optional): random seed value. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): EffNetB2 feature extractor model.\n",
        "        transforms (torchvision.transforms): EffNetB2 image transforms.\n",
        "    \"\"\"\n",
        "    # Create EffNetB2 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.efficientnet_b2(weights=weights)\n",
        "\n",
        "    # Freeze all layers in base model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Change classifier head with random seed for reproducibility\n",
        "    torch.manual_seed(seed)\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Dropout(p=0.3, inplace=True),\n",
        "        nn.Linear(in_features=1408, out_features=num_classes),\n",
        "    )\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-Q048EkzjuQ",
        "outputId": "950e5070-7573-40e4-978a-c8945bf518c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demos/foodvision/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demos/foodvision/app.py\n",
        "### 1. Imports and class names setup ###\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from model import create_effnetb2_model\n",
        "\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "\n",
        "# Setup class names\n",
        "with open(\"demos/foodvision/class_names.txt\", \"r\") as f:# reading them in from class_names.txt\n",
        "    class_names = [food_name.strip() for food_name in  f.readlines()]\n",
        "\n",
        "### 2. Model and transforms preparation ###\n",
        "\n",
        "# Create model\n",
        "effnetb2, effnetb2_transforms = create_effnetb2_model(\n",
        "    num_classes=101, # could also use len(class_names)\n",
        ")\n",
        "\n",
        "# Load saved weights\n",
        "effnetb2.load_state_dict(\n",
        "    torch.load(\n",
        "    f=os.path.join(\"demos\", \"foodvision\", \"pretrained_effnetb2.pth\"),\n",
        "    map_location=torch.device(\"cpu\")\n",
        ")\n",
        "\n",
        ")\n",
        "\n",
        "### 3. Predict function ###\n",
        "\n",
        "# Create predict function\n",
        "def predict(img) -> Tuple[Dict, float]:\n",
        "    \"\"\"Transforms and performs a prediction on img and returns prediction and time taken.\n",
        "    \"\"\"\n",
        "    # Start the timer\n",
        "    start_time = timer()\n",
        "\n",
        "    # Transform the target image and add a batch dimension\n",
        "    img = effnetb2_transforms(img).unsqueeze(0)\n",
        "\n",
        "    # Put model into evaluation mode and turn on inference mode\n",
        "    effnetb2.eval()\n",
        "    with torch.inference_mode():\n",
        "        # Pass the transformed image through the model and turn the prediction logits into prediction probabilities\n",
        "        pred_probs = torch.softmax(effnetb2(img), dim=1)\n",
        "\n",
        "    # Create a prediction label and prediction probability dictionary for each prediction class (this is the required format for Gradio's output parameter)\n",
        "    pred_labels_and_probs = {class_names[i]: float(pred_probs[0][i]) for i in range(len(class_names))}\n",
        "\n",
        "    # Calculate the prediction time\n",
        "    pred_time = round(timer() - start_time, 5)\n",
        "\n",
        "    # Return the prediction dictionary and prediction time\n",
        "    return pred_labels_and_probs, pred_time\n",
        "\n",
        "### 4. Gradio app ###\n",
        "\n",
        "# Create title, description and article strings\n",
        "title = \"FoodVision\"\n",
        "description = \"An EfficientNetB2 feature extractor computer vision model to classify images of food into [101 different classes](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/food101_class_names.txt).\"\n",
        "article = \"Created using PyTorch \"\n",
        "\n",
        "# Create examples list from \"examples/\" directory\n",
        "example_list = [[\"examples/\" + example] for example in os.listdir(os.path.join(\"demos\", \"foodvision\", \"examples\"))]\n",
        "\n",
        "# Create Gradio interface\n",
        "demo = gr.Interface(\n",
        "    fn=predict,\n",
        "    inputs=gr.Image(type=\"pil\"),\n",
        "    outputs=[\n",
        "        gr.Label(num_top_classes=5, label=\"Predictions\"),\n",
        "        gr.Number(label=\"Prediction time (s)\"),\n",
        "    ],\n",
        "    examples=example_list,\n",
        "    title=title,\n",
        "    description=description,\n",
        "    article=article,\n",
        ")\n",
        "\n",
        "# Launch the app!\n",
        "demo.launch(share=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XpDIy1Wvzecg",
        "outputId": "174b6407-cb51-4d46-b99a-f0d404f5e00c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demos/foodvision/app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "%%writefile demos/foodvision/requirements.txt\n",
        "torch==1.12.0\n",
        "torchvision==0.13.0\n",
        "gradio==3.1.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk15dFp0zyQO",
        "outputId": "4d21682b-47fa-4330-eab7-e6be926a771f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting demos/foodvision/requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip foodvision_big folder but exclude certain files\n",
        "!cd demos/foodvision && zip -r ../foodvision.zip * -x \"*.pyc\" \"*.ipynb\" \"*__pycache__*\" \"*ipynb_checkpoints*\"\n",
        "\n",
        "# Download the zipped FoodVision Big app (if running in Google Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    files.download(\"demos/foodvision.zip\")\n",
        "except:\n",
        "    print(\"Not running in Google Colab, can't use google.colab.files.download()\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "Y8Yq1MwQ04OZ",
        "outputId": "821a0021-c4f2-45f7-e3cc-07288be8b1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: app.py (deflated 56%)\n",
            "updating: class_names.txt (deflated 45%)\n",
            "updating: examples/ (stored 0%)\n",
            "updating: examples/Example.jpg (deflated 1%)\n",
            "updating: model.py (deflated 56%)\n",
            "updating: pretrained_effnetb2.pth (deflated 8%)\n",
            "updating: requirements.txt (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_29c375da-7f73-4406-ba6c-5941ec009042\", \"foodvision.zip\", 29351505)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demos/foodvision/app.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D9_PCy9887y",
        "outputId": "8b50f3fc-ba26-4920-9c36-ba81797e5ae9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "* Running on local URL:  http://127.0.0.1:7860\n",
            "* Running on public URL: https://8f31afeb3036cb9b7b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3075, in block_thread\n",
            "    time.sleep(0.1)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/demos/foodvision/app.py\", line 82, in <module>\n",
            "    demo.launch(share=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 2981, in launch\n",
            "    self.block_thread()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/blocks.py\", line 3079, in block_thread\n",
            "    self.server.close()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/gradio/http_server.py\", line 69, in close\n",
            "    self.thread.join(timeout=5)\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1123, in join\n",
            "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
            "  File \"/usr/lib/python3.11/threading.py\", line 1139, in _wait_for_tstate_lock\n",
            "    if lock.acquire(block, timeout):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n",
            "Killing tunnel 127.0.0.1:7860 <> https://8f31afeb3036cb9b7b.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SWIFT"
      ],
      "metadata": {
        "id": "ChEzTWdYyhFw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install coremltools\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WU_fuiteB0bn",
        "outputId": "8953ef58-45c2-4eb2-c3f3-769fdbdd60e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting coremltools\n",
            "  Downloading coremltools-8.3.0-cp311-none-manylinux1_x86_64.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.11/dist-packages (from coremltools) (2.0.2)\n",
            "Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from coremltools) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from coremltools) (1.14.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from coremltools) (4.67.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from coremltools) (24.2)\n",
            "Requirement already satisfied: attrs>=21.3.0 in /usr/local/lib/python3.11/dist-packages (from coremltools) (25.3.0)\n",
            "Collecting cattrs (from coremltools)\n",
            "  Downloading cattrs-25.1.1-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pyaml (from coremltools)\n",
            "  Downloading pyaml-25.5.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from cattrs->coremltools) (4.14.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from pyaml->coremltools) (6.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->coremltools) (1.3.0)\n",
            "Downloading coremltools-8.3.0-cp311-none-manylinux1_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cattrs-25.1.1-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.4/69.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.5.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, cattrs, coremltools\n",
            "Successfully installed cattrs-25.1.1 coremltools-8.3.0 pyaml-25.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import coremltools as ct\n",
        "\n",
        "# 1. Recreate the model architecture\n",
        "effnetb2, _ = create_effnetb2_model(num_classes=101)\n",
        "\n",
        "# 2. Load saved weights\n",
        "effnetb2.load_state_dict(torch.load(\"demos/foodvision/pretrained_effnetb2.pth\", map_location=\"cpu\"))\n",
        "effnetb2.eval()\n",
        "\n",
        "# 3. Create dummy input\n",
        "example_input = torch.rand(1, 3, 224, 224)\n",
        "\n",
        "# 4. Trace the model\n",
        "traced_model = torch.jit.trace(effnetb2, example_input)\n",
        "\n",
        "# 5. Convert to CoreML\n",
        "mlmodel = ct.convert(\n",
        "    traced_model,\n",
        "    inputs=[ct.ImageType(shape=example_input.shape)],\n",
        ")\n",
        "\n",
        "# 6. Save as .mlmodel\n",
        "mlmodel.save(\"/content/drive/MyDrive/Food101/pretrained_effnetb2.mlpackage\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxlzGHsirErB",
        "outputId": "2adbaaeb-34af-427d-f17c-8e542ff2ec1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:coremltools:When both 'convert_to' and 'minimum_deployment_target' not specified, 'convert_to' is set to \"mlprogram\" and 'minimum_deployment_target' is set to ct.target.iOS15 (which is same as ct.target.macOS12). Note: the model will not run on systems older than iOS15/macOS12/watchOS8/tvOS15. In order to make your model run on older system, please set the 'minimum_deployment_target' to iOS14/iOS13. Details please see the link: https://apple.github.io/coremltools/docs-guides/source/target-conversion-formats.html\n",
            "Converting PyTorch Frontend ==> MIL Ops: 100%|█████████▉| 847/848 [00:00<00:00, 3000.08 ops/s]\n",
            "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 31.56 passes/s]\n",
            "Running MIL default pipeline: 100%|██████████| 89/89 [00:04<00:00, 21.46 passes/s]\n",
            "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 68.55 passes/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = mlmodel.predict({\"input\": example_input.numpy()})\n",
        "out"
      ],
      "metadata": {
        "id": "V2R1pVrOrrq0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KeAjZnlDvo-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h8AdcLCJvx0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VIT"
      ],
      "metadata": {
        "id": "Mb0i7t59oU50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check out ViT heads layer\n",
        "vit = torchvision.models.vit_b_16()\n",
        "vit.heads"
      ],
      "metadata": {
        "id": "Icw017ihoTdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(num_classes:int=101,\n",
        "                     seed:int=42):\n",
        "    \"\"\"Creates a ViT-B/16 feature extractor model and transforms.\n",
        "\n",
        "    Args:\n",
        "        num_classes (int, optional): number of target classes. Defaults to 3.\n",
        "        seed (int, optional): random seed value for output layer. Defaults to 42.\n",
        "\n",
        "    Returns:\n",
        "        model (torch.nn.Module): ViT-B/16 feature extractor model.\n",
        "        transforms (torchvision.transforms): ViT-B/16 image transforms.\n",
        "    \"\"\"\n",
        "    # Create ViT_B_16 pretrained weights, transforms and model\n",
        "    weights = torchvision.models.ViT_B_16_Weights.DEFAULT\n",
        "    transforms = weights.transforms()\n",
        "    model = torchvision.models.vit_b_16(weights=weights)\n",
        "\n",
        "    # Freeze all layers in model\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    # Change classifier head to suit our needs (this will be trainable)\n",
        "    torch.manual_seed(seed)\n",
        "    model.heads = nn.Sequential(nn.Linear(in_features=768, # keep this the same as original model\n",
        "                                          out_features=num_classes)) # update to reflect target number of classes\n",
        "\n",
        "    return model, transforms"
      ],
      "metadata": {
        "id": "7G1gdVunoZgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create ViT model and transforms\n",
        "vit, vit_transforms = create_vit_model(num_classes=101,\n",
        "                                       seed=42)"
      ],
      "metadata": {
        "id": "fGadTT_Eofk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Print ViT feature extractor model summary (uncomment for full output)\n",
        "summary(vit,\n",
        "        input_size=(1, 3, 224, 224),\n",
        "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
        "        col_width=20,\n",
        "        row_settings=[\"var_names\"])"
      ],
      "metadata": {
        "id": "GwqtUdB4ojED"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup ViT DataLoaders\n",
        "train_dataloader_vit, test_dataloader_vit, class_names = create_dataloaders(train_dir=train_dir,\n",
        "                                                                                       test_dir=test_dir,\n",
        "                                                                                       transform=vit_transforms,\n",
        "                                                                                       batch_size=32)"
      ],
      "metadata": {
        "id": "X-7-c4otokkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setup optimizer\n",
        "optimizer = torch.optim.Adam(params=vit.parameters(),\n",
        "                             lr=1e-3)\n",
        "# Setup loss function\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Train ViT model with seeds set for reproducibility\n",
        "set_seeds()\n",
        "vit_results = train(model=vit,\n",
        "                           train_dataloader=train_dataloader_vit,\n",
        "                           test_dataloader=test_dataloader_vit,\n",
        "                           epochs=10,\n",
        "                           optimizer=optimizer,\n",
        "                           loss_fn=loss_fn,\n",
        "                           device=device)"
      ],
      "metadata": {
        "id": "1FHc-GScottS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "plot_loss_curves(vit_results)"
      ],
      "metadata": {
        "id": "Ha0U5mo-ovxl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "11PzwkqDcRmas6f4gpMbROts2ZaKzK0-_",
      "authorship_tag": "ABX9TyNLSlkkAOPvaJBxIIsdnwDM",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}